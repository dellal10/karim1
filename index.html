<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Laboratory of Imaging Over Network</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Merriweather+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="./stylesheets/bootstrap.min.css">
    <link rel="stylesheet" href="./stylesheets/colors.css">
    <link rel="shortcut icon" href="./images/Research Team moto Logo Edit-01.png" type="image/x-icon" />
  </head>
  <body class="bg-light">
    <!-- Top Section, For the Logo and the Welcoming Statement-->

    <div class="jumbotron jumbotron-fluid m-0 bg-dark-blue">
      <img src="./images/Research Team moto Logo-03.png" class=" mx-auto d-block" alt="">
      <p class="lead text-center text-light">Research Team @INTTIC</p>
    </div>

    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark-blue sticky-top shadow-sm p-4">
      <div class="container">
        <!-- Navbar Logo -->
        <a class="navbar-brand" href="index.html">
          <img src="./images/Research Team moto Logo-041.png" height="70" alt="">
        </a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarNavDropdown">
          <ul class="navbar-nav h4 m-auto ml-auto">
            <li class="nav-item ml-3">
              <a class="nav-link" href="#about">About</a>
            </li>
            <li class="nav-item ml-3">
              <a class="nav-link" href="#researchAreas">Research</a>
            </li>
            <li class="nav-item ml-3">
              <a class="nav-link" href="#publications">Publications</a>
            </li>
            <li class="nav-item ml-3">
              <a class="nav-link" href="#team">Team</a>
            </li>
            <li class="nav-item ml-3">
              <a class="nav-link" href="#awards">Awards</a>
            </li>
            <li class="nav-item ml-3">
              <a class="nav-link" href="#contact">Contact</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>


    <div class="container-fluid">
      <div class="row p-0">

        <div class="modals">

          <div class="modal fade" id="exampleModalLong1" tabindex="-1" role="dialog" aria-labelledby="exampleModalLongTitle" aria-hidden="true">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLongTitle">Welcome to the four new members</h5>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                    <span aria-hidden="true">&times;</span>
                  </button>
                </div>
                <div class="modal-body">
                  <p>
                    Engineer Students :
                    <ul>
                      <li>Anouar Kherchouche</li>
                      <li>Ibrahim DJEMAI</li>
                      <li>Karim DELLAL</li>
                      <li>Zoubida Ameur</li>
                    </ul>
                  </p>
                </div>
                <div class="modal-footer">
                  <button type="button" class="btn btn-info" data-dismiss="modal">Close</button>
                </div>
              </div>
            </div>
          </div>

          <div class="modal fade" id="exampleModalLong2" tabindex="-1" role="dialog" aria-labelledby="exampleModalLongTitle" aria-hidden="true">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLongTitle">a Defense against Adversarial Attacks using Deep Denoising Sparse Autoencoder</h5>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                    <span aria-hidden="true">&times;</span>
                  </button>
                </div>
                <div class="modal-body">
                  <h4 class="h4">Abstract</h4>
                  <p class="text-justify">
                    Given their outstanding performance, the Deep Neural Networks (DNNs) models have
been deployed in many real-world applications. However, recent studies have demonstrated that they are
vulnerable to small carefully crafted perturbations, i.e., adversarial examples, which considerably decrease
their performance and can lead to devastating consequences, especially for safety-critical applications, such
as autonomous vehicles, healthcare and face recognition. Therefore, it is of paramount importance to offer
defense solutions that increase the robustness of DNNs against adversarial attacks. In this paper, we propose
a novel defense solution based on a Deep Denoising Sparse Autoencoder (DDSA). The proposed method
is performed as a pre-processing step, where the adversarial noise of the input samples is removed before
feeding the classifier. The pre-processing defense block can be associated with any classifier, without any
change to their architecture or training procedure. In addition, the proposed method is a universal defense,
since it does not require any knowledge about the attack, making it usable against any type of attack.
The experimental results on MNIST and CIFAR-10 datasets have shown that the proposed DDSA defense
provides a high robustness against a set of prominent attacks under white-, gray- and black-box settings, and
outperforms state-of-the-art defense methods.
                  </p>
                </div>
                <div class="modal-footer">
                  <button type="button" class="btn btn-info" data-dismiss="modal">Close</button>
                </div>
              </div>
            </div>
          </div>

          <div class="modal fade" id="exampleModalLong3" tabindex="-1" role="dialog" aria-labelledby="exampleModalLongTitle" aria-hidden="true">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLongTitle">Visual Security Assessment of Selective Video Encryption</h5>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                    <span aria-hidden="true">&times;</span>
                  </button>
                </div>
                <div class="modal-body">
                  <h4 class="h4">Abstract</h4>
                  <p class="text-justify">
                    Given the wide use of videos in various applications
and across different devices, this raises the question of their
security and confidentiality. In the last decade, many video
encryption methods have been proposed in the literature. Accordingly, it becomes necessary to have a reliable assessment tool
allowing evaluation of the efficiency of these video encryption
methods, especially from the visual security point of view. Usually,
the visual security is evaluated through the classical objective
signal-based metrics. However, these metrics showed their limits
as visual security metric, since they are not designed to deal
with the security requirements, such as the determination of
content intelligibility. Despite its obvious importance, very few
visual security metrics have been proposed for the assessment
of video encryption methods. This is mainly due to the lack of
ground truth with subjective human scores for video encryption
applications. In this paper, we present a new database for visual
security assessment of selective video encryption. The database
including unencrypted and encrypted video contents generated
using different selective encryption schemes, as well as subjective
scores, is publicly available to help designing new visual security
metrics.
                  </p>
                </div>
                <div class="modal-footer">
                  <button type="button" class="btn btn-info" data-dismiss="modal">Close</button>
                </div>
              </div>
            </div>
          </div>

          <div class="modal fade" id="exampleModalLong4" tabindex="-1" role="dialog" aria-labelledby="exampleModalLongTitle" aria-hidden="true">
            <div class="modal-dialog modal-lg" role="document">
              <div class="modal-content">
                <div class="modal-header">
                  <h5 class="modal-title" id="exampleModalLongTitle">Perceptual Evaluation of Adversarial Attacks for CNN-based Image Classification</h5>
                  <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                    <span aria-hidden="true">&times;</span>
                  </button>
                </div>
                <div class="modal-body">
                  <h4 class="h4">Abstract</h4>
                  <p class="text-justify">
                    Deep neural networks (DNNs) have recently
achieved state-of-the-art performance and provide significant
progress in many machine learning tasks, such as image classification, speech processing, natural language processing, etc.
However, recent studies have shown that DNNs are vulnerable
to adversarial attacks. For instance, in the image classification
domain, adding small imperceptible perturbations to the input
image is sufficient to fool the DNN and to cause misclassification.
The perturbed image, called adversarial example, should be
visually as close as possible to the original image. However, all
the works proposed in the literature for generating adversarial
examples have used the Lp norms (L0, L2 and L∞) as distance
metrics to quantify the similarity between the original image
and the adversarial example. Nonetheless, the Lp norms do not
correlate with human judgment, making them not suitable to
reliably assess the perceptual similarity/fidelity of adversarial
examples. In this paper, we present a database for visual fidelity
assessment of adversarial examples. We describe the creation of
the database and evaluate the performance of fifteen state-ofthe-art full-reference (FR) image fidelity assessment metrics that
could substitute Lp norms. The database as well as subjective
scores are publicly available to help designing new metrics for
adversarial examples and to facilitate future research works.
                  </p>
                </div>
                <div class="modal-footer">
                  <button type="button" class="btn btn-info" data-dismiss="modal">Close</button>
                </div>
              </div>
            </div>
          </div>

        </div>

        <div class="col-md-3 shadow-sm p-4">
          <div class="fixed-col sticky-top">
            <h2 class="text-center">Latest News</h2>

            <div class="list-group shadow-sm ">
              <a href="#" class="list-group-item list-group-item-action" data-toggle="modal" data-target="#exampleModalLong1">
                <div class="d-flex w-100 justify-content-between">
                  <h5 class="mb-1">Welcome to the four new members</h5>
                  <small>12/01/2019</small>
                </div>
              </a>
              <a href="#" class="list-group-item list-group-item-action" data-toggle="modal" data-target="#exampleModalLong2">
                <div class="d-flex w-100 justify-content-between">
                  <h5 class="mb-1">IEEE Access, Accepted <span class="badge badge-info">New</span></h5>
                  <small>31/10/2019</small>
                </div>
                <p class="mb-1">Y. Bakhti </p>
              </a>
              <a href="#" class="list-group-item list-group-item-action" data-toggle="modal" data-target="#exampleModalLong3">
                <div class="d-flex w-100 justify-content-between">
                  <h5 class="mb-1">QoMEX 2019, Accepted</h5>
                  <small>15/04/2019</small>
                </div>
                <p class="mb-1">R. Kamraoui</p>
              </a>
              <a href="#" class="list-group-item list-group-item-action" data-toggle="modal" data-target="#exampleModalLong4">
                <div class="d-flex w-100 justify-content-between">
                  <h5 class="mb-1">QoMEX 2019, Accepted</h5>
                  <small>12/01/2019</small>
                </div>
                <p class="mb-1">Y. Bakhti</p>
              </a>
            </div>
          </div>
        </div>

        <div class="col-md shadow-sm p-0 m-0 overflow-auto">
          <div class="m-0 p-4 bg-light-gray shadow-sm">
            <h2 class="text-center anchor" id="about">About</h2>
            <p class="lead text-center">....</p>
          </div>

         <div class="m-0 p-4 bg-light shadow-sm">
            <h2 class="text-center anchor" id="researchAreas">Research Areas</h2>
            <table class="table">
              <tr>
                <td>
                  <ul>
                    <li class="p-2">Multimedia communications</li>
                    <li class="p-2">Image/video coding</li>
                    <li class="p-2">Visual quality assessment</li>
                  </ul>
                </td>
                <td>
                  <li class="p-2">Multimedia quality-of-experience (QoE)</li>
                  <li class="p-2">Immersive multimedia (3D, 360°, light field)</li>
                  <li class="p-2">Deep learning</li>
                </td>
                <td>
                  <li class="p-2">Perceptual-based visual processing</li>
                  <li class="p-2">Visual cloud computing</li>
                  <li class="p-2">Multimedia security and content protection</li>
                </td>
              </tr>
            </table>
          </div>

          <div class="m-0 p-4 bg-light-gray shadow-sm">
            <h2 class="text-center anchor" id="publications">Publications</h2>
            <h4 class="ml-2">Journal</h4>
            <ul class="list-group mb-2">
              <li class="list-group-item">Y. Bakhti, SA. Fezza, W. Hamidouche and O. Déforges, DDSA: a Defense against Adversarial Attacks using Deep Denoising Sparse Autoencoder, IEEE Access, 7 (1), pp. 160397–160407, 2019.</li>
              <li class="list-group-item">SA. Fezza, A. Chetouani and M-C. Larabi, Using distortion and asymmetry determination for blind stereoscopic image quality assessment strategy, Elsevier Journal of Visual Communication and Image Representation (JVCI), vol. 49, pp. 115–128, 2017.</li>
              <li class="list-group-item">SA. Fezza and M-C. Larabi, Perceptually Driven Nonuniform Asymmetric Coding of Stereoscopic 3D Video, IEEE Trans. Circuits Syst. Video Technol. (T-CSVT), 27(10), pp. 2231–2245, 2017.</li>
              <li class="list-group-item">SA. Fezza and M-C. Larabi, Color calibration of multi-view video plus depth for advanced 3D video, Springer Signal, Image and Video Processing (SIVP), 9(Suppl 1), pp. 177–191, 2015.</li>
              <li class="list-group-item">SA. Fezza, M-C. Larabi and K-M. Faraoun, Feature-based Color Correction of Multiview Video for Coding and Rendering Enhancement, IEEE Trans. Circuits Syst. Video Technol. (T-CSVT), 24(9), pp. 1486–1498, 2014. <span class="red">(awarded as the 2015 Algerian Paper of the Year Awards)</span></li>
            </ul>
            <h4 class="ml-2">Book Chapters</h4>
            <ul class="list-group mb-2">
              <li class="list-group-item">SA. Fezza and M-C. Larabi, Ch.10: Color correction for stereo and multi-view coding, in Color Image and Video Enhancement, Celebi, M. Emre, Lecca, Michela, Smolka, Bogdan (Eds.), (pp. 291–314). Springer International Publishing, 2015.</li>
            </ul>
            <h4 class="ml-2">International Conferences</h4>
            <ul class="list-group mb-2">
              <!-- <li class="list-group-item">Authors, Paper Title, Conference / Journal.</li> -->
              <li class="list-group-item">
                SA. Fezza, Y. Bakhti, W. Hamidouche and O. Déforges, Perceptual Evaluation of Adversarial Attacks for CNN-based Image Classification, in Proc. IEEE International Conference on Quality of Multimedia Experience (QoMEX’2019), Berlin, Germany, 2019.
                [<a target="_blank" href="https://arxiv.org/pdf/1906.00204" name="Paper">Paper</a>]
                [<a target="_blank" href="https://github.com/safezza/IQA-CNN-Adversarial-Attacks" name="GitHub Project">Code</a>]
                [<a target="_blank" href="https://drive.google.com/drive/folders/16U4Ecq8t5Dzfvxdy3YqjLwYEl9pTqFNu" name="Database">Database</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, W. Hamidouche, R. A. Kamraoui and O. Déforges, Visual Security Assessment of Selective Video Encryption, in Proc. IEEE International Conference on Quality of Multimedia Experience (QoMEX’2019), Berlin, Germany, 2019.
                [<a target="_blank" href="https://www.researchgate.net/profile/Sid_Ahmed_Fezza/publication/333160008_Visual_Security_Assessment_of_Selective_Video_Encryption/links/5cdec616299bf14d95a2b4b9/Visual-Security-Assessment-of-Selective-Video-Encryption.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                N. Bakir, SA. Fezza, W. Hamidouche and O. Déforges, Subjective Evaluation of Light Field Image Compression Methods based on View Synthesis, in Proc. European Signal Processing Conference (EUSIPCO’2019), Coruña, Spain, 2019.
                [<a target="_blank" href="https://hal-univ-rennes1.archives-ouvertes.fr/hal-02334426/document" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                N. Bakir, W. Hamidouche, O. Déforges, K. Samrouth, SA. Fezza and M. Khalil RDO-based Light Field Image Coding using Convolutional Neural Networks and Linear Approximation, in Proc. IEEE Data Compression Conference (DCC’2019), Snowbird, Utah, USA, 2019.
                [<a target="_blank" href="https://www.researchgate.net/profile/Wassim_Hamidouche2/publication/331823943_RDO-Based_Light_Field_Image_Coding_Using_Convolutional_Neural_Networks_and_Linear_Approximation/links/5ceaf51192851c4eabc1138e/RDO-Based-Light-Field-Image-Coding-Using-Convolutional-Neural-Networks-and-Linear-Approximation.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza and M-C. Larabi, Quality assessment of out-of-focus blurred images based on objects depth ordering and saliency, in Proc. Image Quality and System Performance Conference (IQSP’2018), IS&T International Symposium on Electronic Imaging, Burlingame, CA, USA, 2018.
                [<a target="_blank" href="https://www.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000012/art00020?crawler=true&mimetype=application/pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                S. Biswas, SA. Fezza and M-C. Larabi, Towards Light-Compensated Saliency Prediction for Omnidirectional Images, in Proc. IEEE International Conference on Image Processing Theory, Tools and Applications (IPTA’2017), Montreal, Canada, 2017.
                [<a target="_blank" href="https://www.researchgate.net/profile/Sid_Ahmed_Fezza/publication/323780522_Towards_Light-Compensated_Saliency_Prediction_for_Omnidirectional_Images/links/5aaa8c5245851517881b3398/Towards-Light-Compensated-Saliency-Prediction-for-Omnidirectional-Images.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, A. Chetouani and M-C. Larabi, Universal blind image quality assessment for stereoscopic images, in Proc. IEEE 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON’2016), Hamburg, Germany, 2016.
                [<a target="_blank" href="https://hal.archives-ouvertes.fr/hal-01339854" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                S. Ouddane, K-M. Faraoun, SA. Fezza and M-C. Larabi, Adaptive colorization-based compression for stereoscopic images, in Proc. IEEE 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video (3DTV-CON’2016), Hamburg, Germany, 2016.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7548962/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, M-C. Larabi and K-M. Faraoun, Stereoscopic Image Quality Metric Based on Local Entropy and Binocular Just Noticeable Difference, in Proc. IEEE International Conference on Image Processing (ICIP’2014), Paris, France, 2014. <span class="red">(recognized as the Top 10% papers)</span>
                [<a target="_blank" href="https://www.researchgate.net/profile/Sid_Ahmed_Fezza/publication/277064120_Stereoscopic_image_quality_metric_based_on_local_entropy_and_binocular_just_noticeable_difference/links/55605d2b08ae8c0cab3148a5/Stereoscopic-image-quality-metric-based-on-local-entropy-and-binocular-just-noticeable-difference.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, M-C. Larabi and K-M. Faraoun, Asymmetric Coding of Stereoscopic 3D based on perceptual significance, in Proc. IEEE International Conference on Image Processing (ICIP’2014), Paris, France, 2014. <span class="red">(recognized as the Top 10% papers)</span>
                [<a target="_blank" href="http://www.academia.edu/download/46817101/Asymmetric_coding_of_stereoscopic_3D_bas20160626-8273-xjb708.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, M-C. Larabi and K-M. Faraoun, Asymmetric Coding using Binocular Just Noticeable Difference and Depth Information for Stereoscopic 3D, in Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP’2014), Florence, Italy, 2014.
                [<a target="_blank" href="https://www.researchgate.net/profile/Sid_Ahmed_Fezza/publication/271481504_Asymmetric_coding_using_Binocular_Just_Noticeable_Difference_and_depth_information_for_stereoscopic_3D/links/5560635508ae9963a119aed3/Asymmetric-coding-using-Binocular-Just-Noticeable-Difference-and-depth-information-for-stereoscopic-3D.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza and M-C. Larabi, No-Reference Perceptual Blur Metric for Stereoscopic Images, in Proc. IEEE International Conference on 3D Imaging (IC3D’2014), Liège, Belgium, 2014.
                [<a target="_blank" href="https://www.researchgate.net/profile/Sid_Ahmed_Fezza/publication/279538342_No-reference_perceptual_blur_metric_for_stereoscopic_images/links/55969a9d08ae793d137c771f/No-reference-perceptual-blur-metric-for-stereoscopic-images.pdf" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza and M-C. Larabi, Stereoscopic 3D Image Quality Assessment based on Cyclopean View and Depth Map, in Proc. IEEE International Conference on Consumer Electronics (ICCE’2014), Berlin, Germany, 2014.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/7034289/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza , M-C. Larabi and K-M. Faraoun, Coding and Rendering Enhancement of Multi-View Video By Color Correction, in Proc. IEEE European Workshop on Visual Information Processing (EUVIP’2013), Paris, France, 2013.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/6623971/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                S. Ouddane, SA. Fezza and K-M. Faraoun, Stereo Image Coding: State of the Art, in Proc. IEEE International Workshop on Systems Signal Processing and their Applications (WoSSPA’2013), Tipaza, Algeria, 2013.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/6602348/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza and K-M. Faraoun, New Prediction Structure for Stereoscopic Video Coding Based on the H.264/AVC Standard, in Proc. International Conference on Digital Information and Communication Technology and its Applications (DICTAP’2011), edited by LNCS Springer, vol. 166, Part 7, pp. 762-769, Dijon, France, 2011.
                [<a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-642-21984-9_63" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, K-M. Faraoun and S. Ouddane, A Comparison of Prediction Structures for Multi-view Video Coding based on the H.264/AVC Standard, in Proc. IEEE International Workshop on Systems Signal Processing and their Applications (WoSSPA’2011), pp. 111-114, Tipaza, Algeria, 2011.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/5931426/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza and S. Ouddane, Fast Stereo Matching via Graph Cuts, in Proc. IEEE International Workshop on Systems Signal Processing and their Applications (WoSSPA’2011), pp. 115-118, Tipaza, Algeria, 2011.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/5931427/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">
                SA. Fezza, M-C. Larabi and K-M. Faraoun, Stereoscopic Video Coding Based on the H.264/AVC Standard, in Proc. IEEE International Conference on Machine and Web Intelligence (ICMWI’2010), pp. 476- 478, Algiers, Algeria, 2010.
                [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/5647993/" name="Paper">Paper</a>]
              </li>
              <li class="list-group-item">SA. Fezza and N. Benamrane, Stereo Correspondence using Reduced-Graph Cuts, in Proc. the 9th International Symposium on Programming and Systems (ISPS’2009), Algiers, Algeria, 2009.</li>
              <li class="list-group-item">SA. Fezza, N. Benamrane and H. Zaidi, Optimisation à base de flot de graphe pour la mise en correspondance d’images stéréoscopiques, La 6ème édition du Colloque sur l’Optimisation et les Systèmes d’Information (COSI’2009), Annaba, Algeria, 2009.</li>
              <li class="list-group-item">SA. Fezza and N. Benamrane, Mise en correspondance d’images stéréoscopiques par coupure de graphe utilisant un espace de recherche réduit, La 6ème édition des ateliers de travail sur le traitement et l’analyse de l’information (TAIMA’2009), Hammamet, Tunisia, 2009.</li>
              <li class="list-group-item">SA. Fezza and N. Benamrane, Mise en correspondance d’images stéréoscopiques par coupure de graphe, in Proc. International Conference on Signals and Information Processing (ICSIP’2009), Guelma, Algeria, 2009.</li>
              <li class="list-group-item">SA. Fezza, S. Kouidri and N. Adjir, Compilation of RT-LOTOS specifications into Time Petri Nets, in Proc. International Conference on Signals and Information Processing (ICSIP’2009), Guelma, Algeria, 2009.</li>
            </ul>

          </div>

          <div class="m-0 p-4 bg-light shadow-sm">
            <h2 class="text-center anchor" id="team">Team</h2>
            <h4 class="ml-2 p-2" id="faculty">Faculty</h4>
            <div class="row my-auto">
              <div class="col">
                <div class="card mx-auto shadow-sm bg-light" id="director" style="width: 300px;">
                  <img src="./images/SA_FEZZA.png" class="card-img-top my-3 mx-auto rounded-circle" alt="photo">
                  <div class="card-body border-bottom">
                    <h5 class="card-title text-center">Sid Ahmed Fezza</h5>
                    <p class="card-text text-center">Associate Professor (HDR) <br>Team Head</p>
                  </div>
                  <!-- <ul class="list-inline mx-auto">
                    <li class="list-inline-item"><img src="./images/gmail.png" height="30" alt="email"></li>
                    <li class="list-inline-item"><a href="mailto:sfezza@inttic.dz?Subject=Contact">sfezza@inttic.dz</a> | <a href="mailto:sidahmed.fezza@gmail.com?Subject=Contact">sidahmed.fezza@gmail.com</a></li>
                  </ul> -->

                  <table class="table mx-auto table-borderless table-sm">
                    <tbody>
                      <tr>
                        <td rowspan="2"><img src="./images/gmail.png" class="m-2" height="30" alt="email"></td>
                        <td><a href="mailto:sfezza@inttic.dz?Subject=Contact">sfezza@inttic.dz</a></td>
                      </tr>
                      <tr>
                        <td><a href="mailto:sidahmed.fezza@gmail.com?Subject=Contact">sidahmed.fezza@gmail.com</a></td>
                      </tr>
                    </tbody>
                  </table>

                  <ul class="list-inline mx-auto">
                    <li class="list-inline-item"> <a target="_blank" href="https://scholar.google.com/citations?hl=en&user=D6IKChUAAAAJ&view_op=list_works&sortby=pubdate" name="Google Scholar Profile"><img src="./images/google-scholar.png" height="30" alt="google scholar"></a></li>
                    <li class="list-inline-item"> <a target="_blank" href="https://www.researchgate.net/profile/Sid_Ahmed_Fezza" name="ResearchGate Profile"><img src="./images/researchgate.png" height="30" alt="researchgate"></a></li>
                    <li class="list-inline-item"><a target="_blank" href="https://dz.linkedin.com/in/sidahmedfezza" name="LinkedIn Account"><img src="./images/linkedin.png" height="30" alt="linkedin"></a></li>
                  </ul>
                </div>
              </div>
            </div>

            <h4 class="ml-2 p-2" id="phd">PhD Students</h4>
            <div class=" my-auto row">
              <div class="col">
                <div class="card m-2 mx-auto shadow-sm bg-light" style="width: 250px;">
                  <img src="./images/PHD.jpg" class="card-img-top my-3 mx-auto rounded-circle" alt="photo">
                  <div class="card-body">
                    <h5 class="card-title text-center">Taieb Chachou</h5>
                    <hr>
                    <p class="card-text text-center">Video surveillance, Transcoding, Deep learning, QoE, Cloud</p>
                  </div>
                </div>
              </div>
            </div>

            <h4 class="ml-2 p-2" id="masters">Master/Engineer Students</h4>
            <div class=" my-auto row">
              <div class="col m-4 mx-auto">
                <div class="card m-2 mx-auto shadow-sm bg-light" style="width: 250px;">
                  <img src="./images/Kherchouche.jpg" class="card-img-top my-3 mx-auto rounded-circle" alt="photo">
                  <div class="card-body">
                    <h5 class="card-title text-center">Anouar Kherchouche</h5>
                    <hr>
                    <p class="card-text text-center">Deep neural network, Security, Adversarial attacks, Defense</p>
                  </div>
                </div>
              </div>

              <div class="col m-4 mx-auto">
              <div class="card m-2 mx-auto shadow-sm bg-light" style="width: 250px;">
                <img src="./images/user-3.png" class="card-img-top my-3 mx-auto rounded-circle" alt="photo">
                <div class="card-body">
                  <h5 class="card-title text-center">Ibrahim Djemai</h5>
                  <hr>
                  <p class="card-text text-center">360° image/video, Saliency, Quality assessment, Deep neural network</p>
                </div>
              </div>
            </div>

            <div class="col m-4 mx-auto">
              <div class="card m-2 mx-auto shadow-sm bg-light" style="width: 250px;">
                <img src="./images/karim.jpg" class="card-img-top my-3 mx-auto rounded-circle" alt="photo">
                <div class="card-body">
                  <h5 class="card-title text-center">Karim DELLAL</h5>
                  <hr>
                  <p class="card-text text-center">Image enhancement, Deep neural network, visual cloud computing, complexity</p>
                </div>
              </div>
            </div>

            <div class="col m-4 mx-auto">
              <div class="card m-2 mx-auto shadow-sm bg-light" style="width: 250px;">
                <img src="./images/user-2.png" class="card-img-top my-3 mx-auto rounded-circle" alt="photo">
                <div class="card-body">
                  <h5 class="card-title text-center">Zoubida Ameur</h5>
                  <hr>
                  <p class="card-text text-center">Visual quality assessment, Deep neural network, Codecs, Smartphone cameras</p>
                </div>
              </div>
            </div>

            </div>

            <h4 class="m-2 ml-2 p-2" id="junior">Junior Projects</h4>

              <ul class="bg-light">
                <li class="p-2">TBC</li>
              </ul>

            <h4 class="m-2 ml-2 p-2" id="alumni">Alumni</h2>
            <table class="table table-hover table-responsive">
              <thead>
                <tr>
                  <th scope="col">Name</th>
                  <th scope="col">Research</th>
                  <th scope="col">Degree</th>
                  <th scope="col">Year</th>
                </tr>
              </thead>
              <tbody>
                <!-- <tr>
                  <th scope="row">Nom, Prénom</th>
                  <td>Domaine</td>
                  <td>Diplome</td>
                  <td>l'Année</td>
                </tr> -->
                <tr>
                  <td>Reda Abdellah KAMRAOUI</td>
                  <td>On the use of deep learning for image/video quality assessment</td>
                  <td>Engineer</td>
                  <td>2019</td>
                </tr>
                <tr>
                  <td>Yassine BAKHTI</td>
                  <td>Adversarial attacks and defenses for convolutional neural networks</td>
                  <td>Engineer</td>
                  <td>2019</td>
                </tr>
                <tr>
                  <td>M. A. KERKOURI & A. BENZERROUK</td>
                  <td>Cloud-based video transcoding for surveillance applications</td>
                  <td>Engineer</td>
                  <td>2019</td>
                </tr>
                <tr>
                  <td>Mohammed KHERARBA</td>
                  <td>Transcoding time prediction for load balancing in the cloud</td>
                  <td>Master</td>
                  <td>2018</td>
                </tr>
                <tr>
                  <td>M. BAHO & K. BENZERGA</td>
                  <td>QoE analysis of a video transmission on an LTE/4G network</td>
                  <td>Engineer</td>
                  <td>2017</td>
                </tr>
                <tr>
                  <td>W. AIT YAHIA & Z. MEHALLI</td>
                  <td>Abnormal event detection in crowded scenes based on optical flow and visual saliency</td>
                  <td>Engineer</td>
                  <td>2017</td>
                </tr>
                <tr>
                  <td>Sourodeep BISWAS</td>
                  <td>Visual attention for omnidirectional images</td>
                  <td>Erasmus Master</td>
                  <td>2017</td>
                </tr>
                <tr>
                  <td>Abderrezzaq SENDJASNI</td>
                  <td>Towards content-based video segmentation methods for distributed video coding in the cloud</td>
                  <td>Master</td>
                  <td>2017</td>
                </tr>
                <tr>
                  <td>Oumar MAHAMADOU</td>
                  <td>Face anti-spoofing based on image quality assessment</td>
                  <td>Master</td>
                  <td>2017</td>
                </tr>
              </tbody>
            </table>
          </div>
          <div class="m-0 p-4 bg-light-gray shadow-sm">
            <h2 class="text-center anchor" id="awards">Awards</h2>
            <ul class="bg-light-gray">
              <li class="p-2">2 papers selected as top 10% accepted paper recognition in ICIP 2014 (International Conference on Image Processing).</li>
              <li class="p-2">The Algerian Paper of the Year Awards in 2015 from the Algerian, Computer Science & Engineering category, from the Algerian Network for Academics, Scientists and Researchers (ANASR).</li>
              <li class="p-2">Travel grant winner for ICIP 2014 from IEEE SPS.</li>
              <li class="p-2">Travel grant winner for ICASSP 2014 from IEEE SPS.</li>
            </ul>
          </div>
        </div>
      </div>
      <div class="row bg-dark-blue shadow-sm text-light">
        <div class="col-sm-3 offset-md-4 p-4">
          <div class="container">
            <h2 class="" id="contact">Contact</h2>
            <table class="contact table table-sm table-borderless text-light" style="border-right: 2px solid #fcf9ea;">
                <tr>
                  <td rowspan="2" class="p-1"> <img src="./images/envelope-1.png" height="30" alt="email" style="margin-top: 50%;"> </td>
                  <td>sfezza@inttic.dz</td>
                  <!-- <td rowspan="3" style="border-left: 1px solid #222831;">
                    <img src="./images/Research Team moto Logo Edit-02.png" class="m-auto" height="80" alt="">
                  </td> -->
                </tr>
                <tr>
                  <td>sidahmed.fezza@gmail.com</td>
                </tr>
                <tr>
                  <td class="p-1"><img src="./images/phone-call.png" height="30" alt="telephone"></td>
                  <td>+213 552 82 92 30</td>
                </tr>
                <tr>
                  <td class="p-1"><img src="./images/map-location.png" height="30" alt="location"></td>
                  <td>BP 1518, Oran El M'naouar, 31000 Oran</td>
                </tr>
            </table>
          </div>
        </div>
        <div class="col-sm-3 p-4 my-auto">
          <img src="./images/Research Team moto Logo 2-02.png" class="m-auto text-center" height="150" alt="">
        </div>
      </div>

    </div>
  </body>
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  <script src="./scripts/bootstrap.min.js" charset="utf-8"></script>
  <script src="./scripts/script.js" charset="utf-8"></script>
</html>
